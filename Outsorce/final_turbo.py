import gc
import polars as pl
import pandas as pd
import numpy as np
import os
import json
import logging
from catboost import CatBoostClassifier
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold
from joblib import Parallel, delayed
from tqdm import tqdm

# --- 1. –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø (UTF-8 –¥–ª—è Windows) ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler("log_turbo.txt", encoding='utf-8'),
        logging.StreamHandler()
    ]
)

DATA_DIR = "data/"
META_DIR = "metadata/"

def load_and_prepare():
    logging.info("START: Loading and Engineering Features...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ 600 –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    with open(os.path.join(META_DIR, "smart_extra_features.json"), "r") as f:
        smart_features = json.load(f)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º—Å—è 600 –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–∞–º—è—Ç–∏
    extra_cols = smart_features[:600] 
    
    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¢–†–ï–ô–ù
    train_main = pl.read_parquet(os.path.join(DATA_DIR, "train_main_features.parquet"))
    train_extra = pl.read_parquet(os.path.join(DATA_DIR, "train_extra_features.parquet"), columns=["customer_id"] + extra_cols)
    train_target = pl.read_parquet(os.path.join(DATA_DIR, "train_target.parquet"))

    # –î–æ–±–∞–≤–ª—è–µ–º "–ó–æ–ª–æ—Ç—ã–µ" –∞–≥—Ä–µ–≥–∞—Ç—ã
    train_extra = train_extra.with_columns([
        pl.mean_horizontal(extra_cols).cast(pl.Float32).alias("row_mean"),
        pl.sum_horizontal([(pl.col(c) == 0).cast(pl.Int32) for c in extra_cols]).alias("row_zeros"),
        pl.max_horizontal(extra_cols).cast(pl.Float32).alias("row_max")
    ])
    
    train_df = train_main.join(train_extra, on="customer_id", how="inner").join(train_target, on="customer_id", how="inner").to_pandas()
    
    # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –¢–ï–°–¢
    test_main = pl.read_parquet(os.path.join(DATA_DIR, "test_main_features.parquet"))
    test_extra = pl.read_parquet(os.path.join(DATA_DIR, "test_extra_features.parquet"), columns=["customer_id"] + extra_cols)
    test_extra = test_extra.with_columns([
        pl.mean_horizontal(extra_cols).cast(pl.Float32).alias("row_mean"),
        pl.sum_horizontal([(pl.col(c) == 0).cast(pl.Int32) for c in extra_cols]).alias("row_zeros"),
        pl.max_horizontal(extra_cols).cast(pl.Float32).alias("row_max")
    ])
    test_df = test_main.join(test_extra, on="customer_id", how="inner").to_pandas()
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏: Float64 -> Float32
    for df in [train_df, test_df]:
        floats = df.select_dtypes(include=['float64']).columns
        df[floats] = df[floats].astype(np.float32)

    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ —Å—Ç—Ä–æ–∫–∏
    cat_features = [c for c in train_df.columns if c.startswith("cat_feature")]
    for col in cat_features:
        train_df[col] = train_df[col].astype(str).fillna("NONE")
        test_df[col] = test_df[col].astype(str).fillna("NONE")
        
    return train_df, test_df, cat_features

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (Windows Friendly)
def train_single_product(target_name, train_df, test_df, feature_cols, cat_features):
    try:
        y = train_df[target_name].astype(np.int8)
        # 10 —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        n_splits = 10
        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
        
        target_test_preds = np.zeros(len(test_df), dtype=np.float32)
        
        for fold, (idx_tr, idx_val) in enumerate(skf.split(train_df, y)):
            X_tr, y_tr = train_df.loc[idx_tr, feature_cols], y.iloc[idx_tr]
            X_val, y_val = train_df.loc[idx_val, feature_cols], y.iloc[idx_val]
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã "Extreme" –¥–ª—è –¥–æ–ª–≥–æ–≥–æ –∏ —Ç–æ—á–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
            model = CatBoostClassifier(
                iterations=1500,     # –ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ
                learning_rate=0.03,  # –ú–µ–¥–ª–µ–Ω–Ω—ã–π —à–∞–≥ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                depth=6,
                l2_leaf_reg=5,       # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
                scale_pos_weight=(y_tr == 0).sum() / y_tr.sum() if y_tr.sum() > 0 else 1,
                task_type="GPU",
                devices='0',         # –û–±–∞ –ø–æ—Ç–æ–∫–∞ –¥–µ–ª—è—Ç GPU
                verbose=0,
                early_stopping_rounds=100
            )
            
            model.fit(X_tr, y_tr, cat_features=cat_features, eval_set=(X_val, y_val))
            target_test_preds += model.predict_proba(test_df[feature_cols])[:, 1] / n_splits
            
            del model, X_tr, X_val
            gc.collect()
            
        logging.info(f"‚úÖ Product {target_name} finished.")
        return target_name.replace("target_", "predict_"), target_test_preds
    except Exception as e:
        logging.error(f"‚ùå Error in {target_name}: {e}")
        return target_name.replace("target_", "predict_"), None

# --- –¢–û–ß–ö–ê –í–•–û–î–ê ---
if __name__ == "__main__":
    print("--- TITAN TURBO SCRIPT STARTED ---")
    
    train_df, test_df, cat_features = load_and_prepare()
    gc.collect()

    feature_cols = [c for c in train_df.columns if c.startswith(("num_feature", "cat_feature", "row_"))]
    target_cols = [c for c in train_df.columns if c.startswith("target_")]

    logging.info(f"üöÄ –°–¢–ê–†–¢. –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}. –ü–æ—Ç–æ–∫–æ–≤: 2.")

    # n_jobs=2 —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –≤ 2 —Ä–∞–∑–∞ –∑–∞ —Å—á–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç–∏
    results = Parallel(n_jobs=1)(
        delayed(train_single_product)(t, train_df, test_df, feature_cols, cat_features) 
        for t in tqdm(target_cols, desc="Processing Products")
    )

    logging.info("üì¶ –°–±–æ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞...")
    submission = pd.DataFrame({'customer_id': test_df['customer_id']})
    for col_name, preds in results:
        if preds is not None:
            submission[col_name] = preds
        else:
            submission[col_name] = 0.0 # –ó–∞–≥–ª—É—à–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ

    sub_path = "SUBMISSION_TITAN_EXTREME_10FOLD.parquet"
    submission.to_parquet(sub_path)
    logging.info(f"üèÜ –í–°–Å –ì–û–¢–û–í–û! –§–∞–π–ª: {sub_path}")