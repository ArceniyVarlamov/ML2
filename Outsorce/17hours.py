import gc
import polars as pl
import pandas as pd
import numpy as np
import os
import json
from catboost import CatBoostClassifier, Pool
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold
from tqdm.notebook import tqdm

# --- 1. –ü–û–î–ì–û–¢–û–í–ö–ê –ò –û–¢–ë–û–† 600 –§–ò–ß–ï–ô ---
DATA_DIR = "data/"
os.makedirs("models_cv", exist_ok=True)
os.makedirs("oof_preds", exist_ok=True)

print("üîç –û—Ç–±–æ—Ä –¢–û–ü-600 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
report = pd.read_csv("feature_importance_report.csv", index_col=0)
# –ë–µ—Ä–µ–º –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –Ω–∞–±–æ—Ä —É–Ω–∏–≤–µ—Ä—Å–∞–ª–æ–≤ –∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤
universal = report.sort_values('mean_importance', ascending=False).head(400).index.tolist()
specialists = []
for t in [c for c in report.columns if c.startswith('target_')]:
    specialists.extend(report.sort_values(t, ascending=False).head(30).index.tolist())
big_smart_features = list(set(universal + specialists))[:600] # –û–≥—Ä–∞–Ω–∏—á–∏–º—Å—è 600 –¥–ª—è –ø–∞–º—è—Ç–∏

# --- 2. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ---
print(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ 100% –¥–∞–Ω–Ω—ã—Ö —Å {len(big_smart_features)} —ç–∫—Å—Ç—Ä–∞-—Ñ–∏—á–∞–º–∏...")
train_main = pl.read_parquet(f"{DATA_DIR}train_main_features.parquet")
train_target = pl.read_parquet(f"{DATA_DIR}train_target.parquet")
train_extra = pl.read_parquet(f"{DATA_DIR}train_extra_features.parquet", columns=["customer_id"] + big_smart_features)

train_df = train_main.join(train_extra, on="customer_id", how="inner").join(train_target, on="customer_id", how="inner").to_pandas()
del train_main, train_extra, train_target
gc.collect()

test_main = pl.read_parquet(f"{DATA_DIR}test_main_features.parquet")
test_extra = pl.read_parquet(f"{DATA_DIR}test_extra_features.parquet", columns=["customer_id"] + big_smart_features)
test_df = test_main.join(test_extra, on="customer_id", how="inner").to_pandas()
del test_main, test_extra
gc.collect()

feature_cols = [c for c in train_df.columns if c.startswith(("num_feature", "cat_feature"))]
target_cols = [c for c in train_df.columns if c.startswith("target_")]
cat_features = [c for c in feature_cols if c.startswith("cat_")]

for col in cat_features:
    train_df[col] = train_df[col].astype(str).fillna("NONE")
    test_df[col] = test_df[col].astype(str).fillna("NONE")

# --- 3. –ö–†–û–°–°-–í–ê–õ–ò–î–ê–¶–ò–Ø –ò –û–ë–£–ß–ï–ù–ò–ï (LONG RUN) ---
n_splits = 5
skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

oof_predictions = pd.DataFrame(index=train_df.index)
final_test_predictions = pd.DataFrame(index=test_df.index)
final_test_predictions['customer_id'] = test_df['customer_id']

overall_scores = []

print(f"üöÄ –°–¢–ê–†–¢ –ù–û–ß–ù–û–ì–û –ü–†–û–ì–û–ù–ê: 5-Fold CV –Ω–∞ GPU")
print(f"–ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: 5-8 —á–∞—Å–æ–≤. –°–ø–æ–∫–æ–π–Ω–æ–π –Ω–æ—á–∏! üåô")

for target in tqdm(target_cols, desc="Targets"):
    y = train_df[target]
    oof_target = np.zeros(len(train_df))
    test_target_preds = np.zeros(len(test_df))
    
    # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ü–∏–∫–ª –ø–æ —Ñ–æ–ª–¥–∞–º
    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y)):
        X_train, y_train = train_df.loc[train_idx, feature_cols], y.iloc[train_idx]
        X_val, y_val = train_df.loc[val_idx, feature_cols], y.iloc[val_idx]
        
        ratio = (y_train == 0).sum() / (y_train == 1).sum() if y_train.sum() > 0 else 1
        
        model = CatBoostClassifier(
            iterations=2000, # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –≤—ã—É—á–∏–≤–∞–Ω–∏—è
            learning_rate=0.03, # –°–Ω–∏–∑–∏–ª–∏ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            depth=6,
            scale_pos_weight=ratio,
            loss_function='Logloss',
            eval_metric='Logloss',
            random_seed=fold + 42, # –†–∞–∑–Ω—ã–π —Å–∏–¥ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–æ–ª–¥–∞
            verbose=0,
            task_type="GPU",
            devices='0',
            early_stopping_rounds=100
        )
        
        model.fit(X_train, y_train, cat_features=cat_features, eval_set=(X_val, y_val))
        
        # OOF –ø—Ä–æ–≥–Ω–æ–∑
        oof_target[val_idx] = model.predict_proba(X_val)[:, 1]
        # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —Ç–µ—Å—Ç (—É—Å—Ä–µ–¥–Ω—è–µ–º)
        test_target_preds += model.predict_proba(test_df[feature_cols])[:, 1] / n_splits
        
        del model
        gc.collect()
        
    # –°—á–∏—Ç–∞–µ–º —Å–∫–æ—Ä –¥–ª—è —Ç–∞—Ä–≥–µ—Ç–∞ –ø–æ OOF
    score = roc_auc_score(y, oof_target)
    overall_scores.append(score)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    oof_predictions[target] = oof_target
    final_test_predictions[target.replace("target_", "predict_")] = test_target_preds

# --- 4. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ---
mean_cv_score = np.mean(overall_scores)
print(f"\nüèÜ –§–ò–ù–ê–õ–¨–ù–´–ô CV ROC-AUC: {mean_cv_score:.6f}")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º OOF –¥–ª—è —Å—Ç–µ–∫–∏–Ω–≥–∞
oof_predictions.to_parquet(f"oof_preds/oof_catboost_cv_{mean_cv_score:.4f}.parquet")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∞–±–º–∏—Ç
sub_name = f"SUBMISSION_FINAL_CV_{mean_cv_score:.4f}.parquet"
final_test_predictions.to_parquet(sub_name)

print(f"üíæ –°–∞–±–º–∏—Ç –≥–æ—Ç–æ–≤: {sub_name}")