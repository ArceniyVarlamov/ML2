Текущие 0.838–0.8384 выглядят как «потолок» для одиночного CatBoost с урезанным extra-набором (600 фич) и без полноценного ансамбля/стекинга. Лидеры ~0.849 почти наверняка получены комбинацией: **(а) шире признаки**, **(б) более разнообразные модели**, **(в) 2‑уровневый стекинг/блендинг с весами по OOF**, **(г) аккуратная схема фолдов**. Ниже — план, который обычно закрывает разрыв ~0.01 по Macro AUC в таких задачах.

---

## 1) Главный принцип метрики: AUC = ранжирование
- Macro ROC-AUC не чувствителен к калибровке вероятностей и монотонным преобразованиям (логит/сигмоида/скейл).
- Поэтому **rank-blend** (как вы делаете) — правильный базовый инструмент.
- Но «смешать 2 похожих CatBoost» часто дает +0.0005…0.002. Чтобы вытащить +0.01, нужна **диверсификация** и **стекинг**.

---

## 2) Фолды: сейчас у вас слабое место для ансамблей и стекинга
Сейчас вы делаете StratifiedKFold *отдельно на каждый таргет*. Для одиночной модели это ок, но:
- OOF-предсказания разных таргетов получаются из **разных разбиений** → неудобно/грязно для межтаргетного стекинга.
- Публичный лидерборд часто «поощряет» модели, которые стабильно обобщаются; хаотика фолдов ухудшает стабильность.

Что обычно работает лучше:
- **Единая разметка фолдов для всех 41 таргета**, сделанная “мульти-лейбл стратификацией” (итеративная стратификация) или суррогатом: стратифицировать по (кол-во положительных меток на объект) + 1–3 самых частотных таргета.
- Тогда вы сможете честно строить:
  - OOF для каждого базового алгоритма,
  - 2‑й уровень (meta) без утечек,
  - подбор весов бленда по OOF.

---

## 3) Признаки: 600 extra-фич почти наверняка мало
Топовые решения обычно используют **гораздо больше информации из extra**, но без взрыва памяти/времени.

### 3.1 Расширить набор extra-фич (не обязательно все 2000+)
Практика: переход с 600 → 1200–1800 отобранных часто дает заметный прирост, особенно если:
- отбор делается **не только по “mean importance”**, а:
  - по пер-таргет важности (ваши “specialists” — правильно),
  - + по стабильности важности между фолдами,
  - + выкидывать «шумные» (важность скачет, а gain маленький).

### 3.2 Дешевые агрегаты по extra (это реально сильный буст)
Ваши `row_mean / row_zeros / row_max` — хорошее начало, но обычно добавляют ещё:
- `row_min`, `row_std`, `row_sum`, `row_median` (или робастный аналог),
- `count_nan`/`count_null` (важно, т.к. пропусков много),
- доля нулей, доля отрицательных/положительных,
- несколько квантили (например низкий/высокий), если есть выбросы.

Эти агрегаты дают модели «контекст» по строке и часто повышают AUC на редких продуктах.

### 3.3 Категории
CatBoost и так неплохо справляется, но проверьте именно логику пропусков:
- пропуск = отдельная категория (вы так делаете) — хорошо,
- частотность категорий (frequency encoding) иногда добавляет сигнал даже поверх CatBoost (особенно если потом использовать ещё и LightGBM/линейные модели).

---

## 4) Модели: нужен «зоопарк», а не один CatBoost
Чтобы бленд реально сдвинулся к 0.849+, модели должны ошибаться по-разному.

Минимальный “набор разнообразия”, который обычно дает прирост:
1) **CatBoost** (несколько конфигураций)
   - разные глубины (6/8/10),
   - разные режимы бутстрэпа/сэмплинга (чтобы декоррелировать),
   - разные сиды.
2) **LightGBM** (или XGBoost) на числах + обработанные категории  
   Часто LGBM дает другой профиль ошибок и хорошо блендится с CatBoost.
3) **Простая линейная модель** (логрег/ридж) на:
   - частотных/таргет-энкодингах категорий,
   - стандартизированных числах,
   - + агрегатах extra.  
   Да, линейка почти всегда хуже соло, но как компонент ансамбля иногда дает ощутимый вклад через декорреляцию.

---

## 5) Стекинг, который почти всегда лучше простого бленда
Самый “выгодный” следующий шаг после появления 3–6 базовых моделей:

### 5.1 Межмодельный стекинг (уровень-2)
- Признаки для мета-модели: OOF-предсказания базовых моделей (по каждому таргету отдельно).
- Мета-модель на каждый таргет: что-то простое и устойчивое (логрег/ридж/легкий GBDT).
- Для теста: используете усредненные предсказания базовых моделей (по фолдам/сидам) как вход.

Это обычно дает больше, чем «подбирать коэффициенты 0.75/0.25» вручную, потому что мета-модель учится **где кому верить**.

### 5.2 Межтаргетный стекинг (использовать зависимости между продуктами)
В банке продукты коррелируют. Это скрытый сильный сигнал.
- Делаете честные OOF-предикты для всех 41 таргетов (уровень-1).
- Для каждого таргета на уровне-2 добавляете как фичи **OOF-предикты других таргетов** (или топ‑N наиболее коррелирующих).
- Это часто дает заметный прирост именно в macro-усреднении (поднимает «хвост» сложных/редких таргетов).

Важно: только через OOF, иначе будет утечка.

---

## 6) Блендинг: веса надо подбирать **по OOF и по таргетам**
То, что вы делаете rank-blend — правильно, но:
- оптимальные веса **почти никогда не одинаковые для всех 41 таргета**,
- и почти никогда не 0.5/0.5 или 0.75/0.25.

Практика: подобрать веса (пусть даже грубой сеткой) **отдельно для каждого таргета** на OOF — это часто «дешевый» +0.001…0.003 к macro.

---

## 7) Как “хеджировать” private (2 финальных решения)
Раз public/private 30/70, типичная тактика:
- **Финал #1 (агрессивный):** лучший стек + бленд (максимум качества по OOF/public).
- **Финал #2 (консервативный):** более простой/стабильный ансамбль (меньше уровней, меньше риска переобучения на схемах подбора весов), но всё равно диверсифицированный.

---

## 8) Почему ваши текущие прогоны, вероятно, не добьют топ
- 600 extra-фич + 1 семейство моделей (CatBoost) → недостаточно разнообразия.
- Нет полноценного стекинга → вы теряете корреляции между продуктами.
- Ранговый бленд двух похожих моделей → маленький прирост, потолок близко.

---

Если скажете, **какие ресурсы доступны** (1 GPU? сколько RAM? сколько часов на один полный прогон?) и **насколько редкие таргеты** (примерная доля единиц по самым редким), я предложу конкретную “дорожную карту” в 2–3 итерации (что сделать сначала, что потом), чтобы максимально быстро приблизиться к 0.849+.